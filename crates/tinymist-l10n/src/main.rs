//! Tinymist l10n tool.

use std::collections::{HashMap, HashSet};

use clap::Parser;
use rayon::{
    iter::{ParallelBridge, ParallelIterator},
    str::ParallelString,
};

/// Args
#[derive(Debug, Clone, PartialEq, Eq, Parser)]
struct Args {
    /// Dir
    #[clap(long)]
    dir: String,
    /// Output
    #[clap(long)]
    output: String,
}

fn main() {
    let args = Args::parse();

    let mut data = walkdir::WalkDir::new(&args.dir)
        .into_iter()
        .filter_map(|e| e.ok())
        .filter(|e| e.file_type().is_file())
        .filter(|e| e.path().extension().map(|e| e == "ts").unwrap_or(false))
        .par_bridge()
        .flat_map(work)
        .collect::<Vec<_>>();

    data.sort_by(|a, b| a.0.cmp(&b.0));

    // read existing data
    let existing_data = std::fs::read_to_string(&args.output).unwrap_or_default();

    // parse toml
    let mut translations = parse_toml(&existing_data);

    // remove not found keys
    let used = data.iter().map(|e| &e.0).collect::<HashSet<_>>();
    translations.retain(|k, _| used.contains(k));

    // update translations
    for (key, value) in data {
        translations
            .entry(key)
            .or_default()
            .insert("en".to_string(), value);
    }

    // write toml
    let result = write_toml(translations);
    std::fs::write(&args.output, result).unwrap();
}

fn parse_toml(input: &str) -> HashMap<String, HashMap<String, String>> {
    let lines = input
        .par_split('\n')
        .map(|line| line.trim())
        .filter(|line| !line.starts_with('#') && !line.is_empty())
        .collect::<Vec<_>>();

    let mut translations = HashMap::new();
    let mut key = String::new();

    for line in lines {
        if line.starts_with('[') {
            key = line[1..line.len() - 1].to_string();
        } else {
            let equal_index = line.find('=').unwrap();
            let lang = line[..equal_index].trim().to_string();
            let value = line[equal_index + 1..].trim().to_string();

            translations
                .entry(key.clone())
                .or_insert_with(HashMap::new)
                .insert(lang, value);
        }
    }

    translations
}

fn write_toml(translations: HashMap<String, HashMap<String, String>>) -> String {
    let mut result = String::new();

    result.push_str("\n# The translation are partially generated by copilot\n\n");

    for (key, mut data) in translations {
        result.push_str(&format!("[{key}]\n"));

        let en = data.remove("en").unwrap();
        result.push_str(&format!("en = {en}\n"));

        // sort by lang
        let mut data = data.into_iter().collect::<Vec<_>>();
        data.sort_by(|a, b| a.0.cmp(&b.0));

        for (lang, value) in data {
            result.push_str(&format!("{lang} = {value}\n"));
        }
    }

    result
}

const L10N_STR: &str = "l10nStr";

fn work(e: walkdir::DirEntry) -> Vec<(String, String)> {
    let path = e.path();
    let content = std::fs::read_to_string(path).unwrap();

    content
        .as_str()
        .par_match_indices('l')
        .flat_map(|e| {
            let s = &content[e.0..];
            if !s.starts_with(L10N_STR) {
                return None;
            }

            let suffix = &content[e.0 + L10N_STR.len()..];
            parse_l10n_args(suffix)
        })
        .collect::<Vec<_>>()
}

fn parse_l10n_args(s: &str) -> Option<(String, String)> {
    let s = parse_char(s, '(')?;
    let (key, _s) = parse_str(s)?;
    // let s = parse_char(s, ',')?;
    // let (value, _s) = parse_str(s)?;
    Some((format!("\"{key}\""), format!("\"{key}\"")))
}

fn parse_char(s: &str, ch: char) -> Option<&str> {
    let s = s.trim_start();
    if s.starts_with(ch) {
        Some(&s[1..])
    } else {
        None
    }
}

fn parse_str(s: &str) -> Option<(&str, &str)> {
    let s = parse_char(s, '"')?;

    let mut escape = false;

    for (i, ch) in s.char_indices() {
        if escape {
            escape = false;
        } else {
            match ch {
                '\\' => escape = true,
                '"' => return Some((&s[..i], &s[i + 1..])),
                _ => (),
            }
        }
    }

    None
}
